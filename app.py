import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import HumanMessage, AIMessage

# ===============================
# ãƒšãƒ¼ã‚¸ã®åŸºæœ¬è¨­å®š
# ===============================
st.set_page_config(
    page_title="Streamlitã¨LangChainã«ã‚ˆã‚‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ",
    page_icon="ğŸ¤–",
    layout="wide"
)

# ===============================
# LLMã®è¨­å®š
# ===============================
llm = ChatOpenAI(
    model_name="gemma3",
    openai_api_base="http://localhost:11434/v1",
    openai_api_key="ollama",
    temperature=0.6,  # å¿œç­”ã®å‰µé€ æ€§ã‚’èª¿æ•´
)

# ===============================
# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å®šç¾©
# ===============================
prompt = ChatPromptTemplate.from_messages([
    ("system", "ã‚ãªãŸã¯å½¹ã«ç«‹ã¤ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¯„ã‚Šæ·»ã£ã¦è³ªå•ã«ã‚„ã•ã—ãã¦ã„ã­ã„ã«ç­”ãˆã¦ãã ã•ã„ã€‚"),
    ("placeholder", "{history}"),  # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´
    ("human", "{input}"),          # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ€æ–°å…¥åŠ›
])

# ===============================
# ãƒã‚§ã‚¤ãƒ³ã®å®šç¾©ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ â†’ LLM â†’ å‡ºåŠ›ãƒ‘ãƒ¼ã‚µãƒ¼ï¼‰
# ===============================
chain = prompt | llm | StrOutputParser()

# ===============================
# é–¢æ•°å®šç¾©ï¼šStreamlitã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã‚’LangChainå½¢å¼ã«å¤‰æ›
# ===============================
def messages_to_langchain(messages):
    """Streamlitã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã‚’LangChainã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ã«å¤‰æ›ã™ã‚‹"""
    langchain_messages = []
    for msg in messages:
        if msg["role"] == "user":
            langchain_messages.append(HumanMessage(content=msg["content"]))
        elif msg["role"] == "assistant":
            langchain_messages.append(AIMessage(content=msg["content"]))
    return langchain_messages

# ===============================
# é–¢æ•°å®šç¾©ï¼šLLMã®å¿œç­”ã‚’å–å¾—
# ===============================
def get_response(chain, history, user_input):
    """LangChainã®ãƒã‚§ã‚¤ãƒ³ã‚’å‘¼ã³å‡ºã—ã¦AIã®å¿œç­”ã‚’å–å¾—ã™ã‚‹"""
    try:
        response = chain.invoke({
            "history": history,  # éå»ã®å±¥æ­´
            "input": user_input  # æœ€æ–°ã®å…¥åŠ›
        })
        # Gemma 3å¯¾å¿œ: <0xE3><0x80><0x80>ã‚’å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã«å¤‰æ›ã—ã¦è¿”ã™
        return response.replace("\u3000", "ã€€")
    except ConnectionError:
        return "âš ï¸ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
    except Exception as e:
        return f"âš ï¸ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

# === ä»¥é™ãŒãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚°ãƒ©ãƒ  ========

# ===============================
# ãƒšãƒ¼ã‚¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¡¨ç¤º
# ===============================
st.title("ğŸ¤– Streamlitã¨LangChainã«ã‚ˆã‚‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")

# ===============================
# Streamlitã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ãŒãªã‘ã‚Œã°åˆæœŸåŒ–ã™ã‚‹
# ===============================
if "messages" not in st.session_state:
    st.session_state.messages = []  # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã‚’ä¿æŒã™ã‚‹ãƒªã‚¹ãƒˆ

# ===============================
# Streamlitã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã‚’è¡¨ç¤º
# ===============================
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ===============================
# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã¨å¿œç­”å‡¦ç†
# ===============================
if user_input := st.chat_input("AIã«èããŸã„ã“ã¨ã‚’æ›¸ã„ã¦ã­"):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’Streamlitã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã«è¿½åŠ ã—ã€è¡¨ç¤º
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # å‡¦ç†ä¸­ã®ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ã‚’è¡¨ç¤º
    with st.spinner("AIãŒè€ƒãˆã¦ã„ã¾ã™..."):
        # Streamlitã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã‚’LangChainå½¢å¼ã«å¤‰æ›ï¼ˆæœ€æ–°ã®å…¥åŠ›ã¯é™¤å¤–ï¼‰
        history = messages_to_langchain(st.session_state.messages[:-1])
        # LLMã®å¿œç­”ã‚’å–å¾—
        response = get_response(chain, history, user_input)

    # å¿œç­”ã‚’Streamlitã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã«è¿½åŠ ã—ã€è¡¨ç¤º
    st.session_state.messages.append({"role": "assistant", "content": response})
    with st.chat_message("assistant"):
        st.markdown(response)
